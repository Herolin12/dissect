{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Dissection (for classifiers)\n",
    "\n",
    "In this notebook, we will examine internal layer representations for a classifier trained to recognize scene categories.\n",
    "\n",
    "Setup matplotlib, torch, and numpy for a high-resolution browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from importlib import reload\n",
    "import IPython\n",
    "mpl.rcParams['lines.linewidth'] = 0.25\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.linewidth'] = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up experiment directory and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, argparse, os, shutil, inspect, json, numpy, math\n",
    "import netdissect\n",
    "from netdissect.easydict import EasyDict\n",
    "from netdissect import pbar, nethook, renormalize, parallelfolder, pidfile\n",
    "from netdissect import upsample, tally, imgviz, imgsave, bargraph, show\n",
    "from experiment import dissect_experiment as experiment\n",
    "\n",
    "# choices are alexnet, vgg16, or resnet152.\n",
    "args = EasyDict(model='vgg16', dataset='places', seg='netpqc', layer='conv5_3', quantile=0.01)\n",
    "resdir = 'results/new-%s-%s-%s-%s-%s' % (args.model, args.dataset, args.seg, args.layer, int(args.quantile * 1000))\n",
    "def resfile(f):\n",
    "    return os.path.join(resdir, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load classifier model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = experiment.load_model(args, instrumented=False) # Don't wrap in InstrumentedModel\n",
    "layername = experiment.instrumented_layername(args)\n",
    "dataset = experiment.load_dataset(args)\n",
    "sample_size = len(dataset)\n",
    "percent_level = 1.0 - args.quantile\n",
    "\n",
    "print('Inspecting layer %s of model %s on %s' % (layername, args.model, args.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load segmenter, segment labels, classifier labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier labels\n",
    "from urllib.request import urlopen\n",
    "from netdissect import renormalize\n",
    "\n",
    "# synset_url = 'http://gandissect.csail.mit.edu/models/categories_places365.txt'\n",
    "# classlabels = [r.split(' ')[0][3:] for r in urlopen(synset_url).read().decode('utf-8').split('\\n')]\n",
    "classlabels = dataset.classes\n",
    "segmodel, seglabels, segcatlabels = experiment.setting.load_segmenter(args.seg)\n",
    "renorm = renormalize.renormalizer(dataset, target='zc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test classifier on some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import renormalize\n",
    "\n",
    "indices = [200, 755, 709, 423, 60, 100, 110, 120]\n",
    "batch = torch.cat([dataset[i][0][None,...] for i in indices])\n",
    "truth = [classlabels[dataset[i][1]] for i in indices]\n",
    "preds = model(batch.cuda()).max(1)[1]\n",
    "imgs = [renormalize.as_image(t, source=dataset) for t in batch]\n",
    "prednames = [classlabels[p.item()] for p in preds]\n",
    "show([[img, 'pred: ' + pred, 'true: ' + gt] for img, pred, gt in zip(imgs, prednames, truth)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segment single image, and visualize the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import imgviz\n",
    "\n",
    "iv = imgviz.ImageVisualizer(120, source=dataset)\n",
    "seg = segmodel.segment_batch(renorm(batch).cuda(), downsample=4)\n",
    "\n",
    "show([(iv.image(batch[i]), iv.segmentation(seg[i,0]),\n",
    "            iv.segment_key(seg[i,0], segmodel))\n",
    "            for i in range(len(seg))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect quantile statistics\n",
    "\n",
    "First, unconditional quantiles over the activations; also keep track of the top 200 activating images for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar.descnext('rq/topk')\n",
    "from netdissect import dissect\n",
    "topk, rq, run = dissect.acts_stats(model, dataset, layer=layername,\n",
    "            k=100,\n",
    "            batch_size=30,\n",
    "            num_workers=30,\n",
    "            cachedir=resdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar.descnext('unit_images')\n",
    "\n",
    "iv = imgviz.ImageVisualizer((100, 100), source=dataset, quantiles=rq,\n",
    "        level=rq.quantiles(percent_level))\n",
    "\n",
    "unit_images = iv.masked_images_for_topk(\n",
    "        run, dataset, topk, k=5, num_workers=30, pin_memory=True,\n",
    "        cachefile=resfile('top5images.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Units\n",
    "\n",
    "Label according to new algorithm where iou is scored only among top-k matching images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dissect)\n",
    "level = rq.quantiles(percent_level)\n",
    "    \n",
    "all_iou = dissect.topk_label_stats_using_segmodel(dataset, segmodel,\n",
    "                 run, level, topk, k=100, downsample=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_iou[:,0] = 0 # ignore the dummy label\n",
    "unit_label_99 = [\n",
    "        (concept.item(), seglabels[concept], segcatlabels[concept], bestiou.item())\n",
    "        for (bestiou, concept) in zip(*all_iou.max(1))]\n",
    "label_list = [labelcat for concept, label, labelcat, iou in unit_label_99 if iou > 0.04]\n",
    "display(IPython.display.SVG(experiment.graph_conceptcatlist(label_list)))\n",
    "len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a few units with their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for u in range(30):\n",
    "    print('unit %d, label %s, iou %.3f' % (u, unit_label_99[u][1], unit_label_99[u][3]))\n",
    "    display(unit_images[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}